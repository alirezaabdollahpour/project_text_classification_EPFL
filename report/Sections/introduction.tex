We address tweet sentiment classification in the EPFL ML text challenge. The dataset provides weak supervision from removed emoticons: tweets in \path{train_pos*.txt} originally contained a positive smiley, and tweets in \path{train_neg*.txt} a negative one. Given only the remaining, whitespace-tokenized text, we predict sentiment for 10{,}000 unlabeled tweets in \path{test_data.txt}. This setting is challenging due to informal language, creative spelling, hashtags, and heavy use of URLs and mentions.

Our report follows an incremental modeling approach \textbf{from simple to more complex}. We begin with strong, fast baselines based on feature hashing and embedding-bag pooling to establish a reliable reference point. Next, we add in-domain GloVe embeddings trained on tweet co-occurrences and evaluate pooled embedding classifiers. Finally, we move to \textbf{pretraining and fine-tuning} by fine-tuning a tweet-pretrained transformer (BERTweet) for binary classification, and we optionally explore a hybrid model that fuses the fine-tuned transformer representation with a pooled GloVe vector to improve robustness on short, noisy tweets.

\paragraph{Results.} Our main findings and contributions are:
\begin{itemize}
  \item \textbf{Strong simple baselines:} hashed n-gram and embedding-bag models provide fast, reproducible reference points for iteration.
  \item \textbf{In-domain embeddings:} we train GloVe on the tweet corpus and show how pooled static embeddings improve over sparse features.
  \item \textbf{Pretraining + fine-tuning:} fine-tuning tweet-pretrained BERTweet yields our strongest model family under a controlled validation protocol.
  \item \textbf{Hybrid fusion:} we test whether combining averaged GloVe features with transformer representations improves robustness.
\end{itemize}
